{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Rocket Transformer Classifier\n",
    "class RocketTransformerClassifier:\n",
    "    def __init__(self):\n",
    "        self.classifiers_mapping = {}\n",
    "\n",
    "    def fit_rocket(self, x_train, y_train, kernels=10000):\n",
    "        # Initialize and fit Rocket transformer\n",
    "        rocket = Rocket(num_kernels=kernels, normalise=False)\n",
    "        rocket.fit(x_train)\n",
    "        x_training_transform = rocket.transform(x_train)\n",
    "\n",
    "        # Normalize the transformed data\n",
    "        scaler = StandardScaler()\n",
    "        x_training_transform = scaler.fit_transform(x_training_transform)\n",
    "\n",
    "        # Train RidgeClassifier with normalized transformed data\n",
    "        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "        classifier.fit(x_training_transform, y_train)\n",
    "\n",
    "        # Store the transformer, scaler, and classifier\n",
    "        self.classifiers_mapping[\"transformer\"] = rocket\n",
    "        self.classifiers_mapping[\"scaler\"] = scaler\n",
    "        self.classifiers_mapping[\"classifier\"] = classifier\n",
    "\n",
    "    def predict_rocket(self, x_test, y_test):\n",
    "        # Retrieve transformer, scaler, and classifier\n",
    "        rocket = self.classifiers_mapping[\"transformer\"]\n",
    "        scaler = self.classifiers_mapping[\"scaler\"]\n",
    "        classifier = self.classifiers_mapping[\"classifier\"]\n",
    "    \n",
    "        # Transform and normalize test data\n",
    "        x_test_transform = rocket.transform(x_test)\n",
    "        x_test_transform = scaler.transform(x_test_transform)\n",
    "    \n",
    "        # Predict and evaluate\n",
    "        predictions = classifier.predict(x_test_transform)\n",
    "        accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "        classification_report = metrics.classification_report(y_test, predictions)\n",
    "    \n",
    "        logger.info(\"-----------------------------------------------\")\n",
    "        logger.info(f\"Accuracy: {accuracy}\")\n",
    "        logger.info(\"\\nConfusion Matrix:\\n\" + str(confusion_matrix))\n",
    "        logger.info(\"\\nClassification Report:\\n\" + classification_report)\n",
    "    \n",
    "        return accuracy, confusion_matrix, classification_report\n",
    "\n",
    "# Define function to load time-series data\n",
    "def load_time_series_data(input_dir):\n",
    "    \"\"\"\n",
    "    Load all time-series CSV files in the input directory and prepare\n",
    "    the data for Rocket classifier.\n",
    "    \"\"\"\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    # Iterate through each CSV file\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "            # Load CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract label and time-series data\n",
    "            label = df.iloc[0]['class']  # 'class' 열에서 라벨을 가져옵니다.\n",
    "            # label = df['class'].iloc[0]  # Assuming 'class' column exists in all files\n",
    "            time_series = df.iloc[:, 3:].values  # Exclude non-time-series columns\n",
    "            \n",
    "            x_data.append(time_series)\n",
    "            y_data.append(label)\n",
    "\n",
    "    return np.array(x_data), np.array(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape: (348, 32, 132)\n",
      "y_data shape: (348,)\n",
      "Sample label: 377\n",
      "Sample time-series data shape: (32, 132)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "input_dir = '/root/juno/time_series_data'  # 데이터 디렉토리 경로\n",
    "x_data, y_data = load_time_series_data(input_dir)\n",
    "\n",
    "# 데이터 확인\n",
    "print(f\"x_data shape: {x_data.shape}\")\n",
    "print(f\"y_data shape: {y_data.shape}\")\n",
    "print(f\"Sample label: {y_data[0]}\")\n",
    "print(f\"Sample time-series data shape: {x_data[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Splitting data into train/test sets...\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "logger.info(\"Splitting data into train/test sets...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing Rocket classifier...\n"
     ]
    }
   ],
   "source": [
    "# Initialize Rocket classifier\n",
    "logger.info(\"Initializing Rocket classifier...\")\n",
    "rocket_classifier = RocketTransformerClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training Rocket classifier...\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "logger.info(\"Training Rocket classifier...\")\n",
    "rocket_classifier.fit_rocket(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Testing Rocket classifier...\n",
      "/root/miniconda3/envs/condatest/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/condatest/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/condatest/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:__main__:-----------------------------------------------\n",
      "INFO:__main__:Accuracy: 0.7714285714285715\n",
      "INFO:__main__:\n",
      "Confusion Matrix:\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "INFO:__main__:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         377       1.00      1.00      1.00         2\n",
      "         378       0.67      1.00      0.80         2\n",
      "         379       0.67      1.00      0.80         2\n",
      "         380       0.33      0.50      0.40         2\n",
      "         381       0.67      1.00      0.80         2\n",
      "         382       1.00      0.50      0.67         2\n",
      "         383       0.67      0.67      0.67         3\n",
      "         384       0.50      0.67      0.57         3\n",
      "         385       1.00      0.50      0.67         2\n",
      "         386       1.00      1.00      1.00         2\n",
      "         387       1.00      0.67      0.80         3\n",
      "         388       1.00      1.00      1.00         2\n",
      "         389       1.00      1.00      1.00         2\n",
      "         390       1.00      0.50      0.67         2\n",
      "         391       0.50      0.50      0.50         2\n",
      "         392       1.00      1.00      1.00         2\n",
      "         393       1.00      1.00      1.00         2\n",
      "         394       0.50      1.00      0.67         2\n",
      "         395       1.00      1.00      1.00         2\n",
      "         396       0.67      1.00      0.80         2\n",
      "         397       1.00      0.33      0.50         3\n",
      "         398       1.00      1.00      1.00         2\n",
      "         399       0.67      0.67      0.67         3\n",
      "         400       0.67      1.00      0.80         2\n",
      "         401       1.00      1.00      1.00         3\n",
      "         402       0.00      0.00      0.00         2\n",
      "         403       1.00      0.50      0.67         2\n",
      "         404       1.00      1.00      1.00         2\n",
      "         405       1.00      1.00      1.00         2\n",
      "         406       0.67      1.00      0.80         2\n",
      "         407       0.50      0.50      0.50         2\n",
      "         408       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.80      0.78      0.76        70\n",
      "weighted avg       0.80      0.77      0.76        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier\n",
    "logger.info(\"Testing Rocket classifier...\")\n",
    "accuracy, confusion_matrix, classification_report = rocket_classifier.predict_rocket(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Results saved to: /root/juno/classification_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the results to a file\n",
    "output_dir = '/root/juno'\n",
    "\n",
    "results_file = os.path.join(output_dir, 'classification_results.txt')\n",
    "with open(results_file, 'w') as f:\n",
    "    f.write(\"Accuracy: {}\\n\".format(accuracy))\n",
    "    f.write(\"\\nConfusion Matrix:\\n\")\n",
    "    f.write(str(confusion_matrix))\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(classification_report)\n",
    "\n",
    "logger.info(\"Results saved to: \" + results_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condatest",
   "language": "python",
   "name": "condatest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
